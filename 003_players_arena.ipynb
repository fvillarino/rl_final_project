{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08877595-17b1-43e5-acda-60b6515254a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7003fe5-24d6-4689-903e-2ff8370d6acc",
   "metadata": {},
   "source": [
    "# Importar entorno y familiarizarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1c580c-9d7a-44a0-adab-d75c9a7dcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f0214-b031-431d-ab8b-5fb7bba5a64e",
   "metadata": {},
   "source": [
    "# Crear 3 tipos de jugador\n",
    "- Random: Selecciona uniformemente una de las acciones válidas\n",
    "- Greedy: Selecciona la acción que le da más ganancia inmediata (cantidad de piezas que come). Si hay más de una acción que da máxima ganancia samplear uniformemente entre ellas\n",
    "- Optimum (solo para 4x4): Usando resultados de la PI optima obtenida por policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9950fc-9ebe-4d31-b733-1a13047f1b87",
   "metadata": {},
   "source": [
    "Tener en cuenta que:\n",
    "- ReversiEnv tiene los métodos get_valid y next_step y no es necesario mantener el estado del entorno\n",
    "- env.PASS ([-1,  0]) es una acción valida posible y debería hacerse cuando no get_valid devuelve una matriz de ceros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ae9f1-4f78-47e2-ac3a-1c65d57e359c",
   "metadata": {},
   "source": [
    "Para el optimo en 4x4 bajar usar la PI obtenida en la notebook anterior guardado en /mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb16660-60b6-4ff3-9129-d2c6d944d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a13031a-8316-4f57-8b7f-557a741c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_valid_actions(state):\n",
    "    # np.argwhere junto con env.get_valid y randint solucionan el problema en pocas lineas pero puede usar otra estrategia\n",
    "    valid_actions = np.argwhere(env.get_valid(state)) # Acciones validas\n",
    "    sampled_valid_action = valid_actions[random.randint(0,len(valid_actions)-1)]\n",
    "    return sampled_valid_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e8269ba-fe4f-476a-b4f1-107c379f8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPlayer():\n",
    "    def __init__(self, player=1, board_shape=None, env=None, flatten_action=False):\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.env = env\n",
    "        self.player = player # player number. 1 o -1\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = self.env.board.shape[0]\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Implementar\n",
    "        # Primero obtengo las acciones válidas\n",
    "        valid_actions = np.argwhere(self.env.get_valid((board,self.player)))     \n",
    "        if len(valid_actions)==0:\n",
    "            print('PASS')\n",
    "            action = self.env.PASS\n",
    "        else:\n",
    "            actions_score = []\n",
    "            for a in valid_actions:\n",
    "                (next_state, _), reward, done, _ = self.env.next_step((board, self.player), a)\n",
    "                actions_score.append(next_state.sum()*self.player)\n",
    "            best_action_score = max(actions_score)\n",
    "            best_actions = valid_actions[np.array(actions_score)==best_action_score]\n",
    "            action = best_actions[random.randint(0,len(best_actions)-1)]\n",
    "        # Tiene que devoler la acción en la que come más piezas.\n",
    "        # A igualdad de piezas comidas, samplear uniformemente\n",
    "        self.env.action_space\n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action\n",
    "        \n",
    "class RandomPlayer():\n",
    "    def __init__(self, player=1, board_shape=None, env=None, flatten_action=False):\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.env = env\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = self.env.board.shape[0]\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Muestrea aleatoriamente las acciones válidas\n",
    "        # Puede usar la función creada en la notebook anterior\n",
    "        #action = sample_valid_actions((board,self.player))\n",
    "        #print(self.env.get_valid((board,self.player)))\n",
    "        mat_valid_actions = self.env.get_valid((board,self.player))\n",
    "        if mat_valid_actions.sum()==0:\n",
    "            print('PASS')\n",
    "            action = self.env.PASS\n",
    "        else:\n",
    "            valid_actions = np.argwhere(mat_valid_actions) # Acciones validas\n",
    "            action = valid_actions[random.randint(0,len(valid_actions)-1)]\n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action\n",
    "        \n",
    "\n",
    "class DictPolicyPlayer():\n",
    "    def __init__(self, player=1, board_shape=4, env=None, flatten_action=False, dict_folder='mdp/pi_mdp.npy'):\n",
    "        self.pi_dict = np.load(dict_folder, allow_pickle=True).item()\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = board_shape\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Elegir la acción optima y devolverla\n",
    "        board_tuple = tuple((board*self.player).reshape(-1))\n",
    "        if board_tuple in self.pi_dict:\n",
    "            action = np.array(self.pi_dict[board_tuple])\n",
    "        else:\n",
    "            print(f'PASS - DICT - Player: {self.player}')\n",
    "            print((board*self.player))\n",
    "            action = np.array([-1, 0])\n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524a08ed-cc63-4c5e-a484-ae33d9867df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0]\n",
      " [ 0  1 -1  0]\n",
      " [ 0 -1  1  0]\n",
      " [ 0  0  0  0]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "board_shape = 4\n",
    "env = ReversiEnv(board_shape=board_shape)\n",
    "(board, player) = env.reset()\n",
    "print(board)\n",
    "print(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13177cfa-40df-4524-a38c-99c626e041bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_valid((board,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c3d0d3e-81d5-4138-ad47-e219dcc2f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GreedyPlayer(player=1, board_shape=4)\n",
    "rp = RandomPlayer(player=1, board_shape=4)\n",
    "op = DictPolicyPlayer(player=1, board_shape=4, flatten_action=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edb2cb3f-90a2-4d3e-9a2a-5e25ac26b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = np.array([\n",
    "         [0,-1,1,-1],\n",
    "         [0,1,1,0],\n",
    "         [0,-1,1,0],\n",
    "         [0,0,0,0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96fe3fee-a446-4439-adb7-ca0b49266664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.predict(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb62131c-a521-414f-9010-9cb09b5c54e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp.predict(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74c06dbf-48ff-4a7b-966c-fb26a3024dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS - DICT\n",
      "[[ 0 -1  1 -1]\n",
      " [ 0  1  1  0]\n",
      " [ 0 -1  1  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.predict(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838c900-4efb-45f5-acdd-241f867e825e",
   "metadata": {},
   "source": [
    "# Verificar que el pass funciona OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73826228-1177-42a7-bf83-b6c2b2204fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GreedyPlayer(player=1, board_shape=8)\n",
    "rp = RandomPlayer(player=1, board_shape=8)\n",
    "op = DictPolicyPlayer(player=1, board_shape=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c214dba4-3ef5-432f-bb40-8d5f399b5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS\n",
      "PASS\n",
      "PASS - DICT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([\n",
    "    [-1, 0, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 0, 0, 0]]\n",
    ")\n",
    "rp.predict(board)\n",
    "gp.predict(board)\n",
    "op.predict(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0e973-3682-480a-9f69-3b381d73cda9",
   "metadata": {},
   "source": [
    "# Completar la función que dado dos jugadores imprima estadísticas de las partidas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60f47a75-560a-415d-8b34-ae4f897d80fe",
   "metadata": {},
   "source": [
    "Por ejemplo:\n",
    "(Las estadísticas son relativas el que se pasa primero en la función)\n",
    "\n",
    "Wins as first: 0.35\n",
    "Wins as second: 0.55\n",
    "Plays as first: 2457\n",
    "Plays as second: 2543\n",
    "Avg game duration: 5.937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edb7cd-d87a-4138-b7c4-e82f4fd68180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef78de3-e74b-41bb-b612-dcab6ec8ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arena_stats(Player_1, Player_2, board_shape, N=500):\n",
    "    \n",
    "    env = ReversiEnv(board_shape=board_shape)\n",
    "    wins_as_first = 0\n",
    "    wins_as_second = 0\n",
    "    plays_as_first = 0\n",
    "    plays_as_second = 0\n",
    "    total_steps = 0\n",
    "    player_1 = Player_1(player=1, board_shape=board_shape, flatten_action=False)\n",
    "    player_2 = Player_2(player=-1, board_shape=board_shape, flatten_action=False) # Implementar\n",
    "    for i in range(N):\n",
    "        # Aveces empieza un jugador, a veces el otro\n",
    "        first_player = np.random.choice([-1, 1])\n",
    "        player_1.player = first_player\n",
    "        player_2.player = -first_player\n",
    "        \n",
    "        plays_as_first = plays_as_first + (first_player == 1)\n",
    "        plays_as_second = plays_as_second + (first_player == -1)\n",
    "        \n",
    "        done = False\n",
    "        n_steps = 0\n",
    "        (board, player) = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            if first_player == player:\n",
    "                action = player_1.predict(board=board)# Juega el jugador 1\n",
    "            else:\n",
    "                action = player_2.predict(board=board)# Juega el jugador 2\n",
    "            (board, player), reward, done, info = env.step(action)\n",
    "            n_steps = n_steps + 1\n",
    "        total_steps = total_steps + n_steps\n",
    "        wins_as_first = wins_as_first + (reward == first_player) * (first_player == 1)\n",
    "        wins_as_second = wins_as_second + (reward == first_player) * (first_player == -1)\n",
    "    print(f'Wins as first: {wins_as_first/plays_as_first}')\n",
    "    print(f'Wins as second: {wins_as_second/plays_as_second}')\n",
    "    print(f'Plays as first: {plays_as_first}')\n",
    "    print(f'Plays as second: {plays_as_second}')\n",
    "    print(f'Avg game duration: {total_steps/N}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0eb85b44-7c8d-4b96-a0fb-a0ab41ff75d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.0\n",
      "Wins as second: 0.1694255111976631\n",
      "Plays as first: 973\n",
      "Plays as second: 1027\n",
      "Avg game duration: 11.7385\n"
     ]
    }
   ],
   "source": [
    "arena_stats( GreedyPlayer,DictPolicyPlayer, 4, N=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f83803e3-b172-44f8-9f9b-413c75975a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.818\n",
      "Wins as second: 1.0\n",
      "Plays as first: 500\n",
      "Plays as second: 500\n",
      "Avg game duration: 11.634\n"
     ]
    }
   ],
   "source": [
    "arena_stats(DictPolicyPlayer, RandomPlayer, 4, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4a4790ea-396c-4691-925d-1e84441ea129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.0\n",
      "Wins as second: 0.125\n",
      "Plays as first: 488\n",
      "Plays as second: 512\n",
      "Avg game duration: 11.684\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, DictPolicyPlayer, 4, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c157f772-2a91-40d4-83f4-6f1ca8fb9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.376\n",
      "Wins as second: 0.394\n",
      "Plays as first: 500\n",
      "Plays as second: 500\n",
      "Avg game duration: 58.115\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, GreedyPlayer, 8, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c38e7e31-8c87-4dd7-8850-6f1575607def",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-383-21417bb53616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marena_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGreedyPlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomPlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-374-794558c7d5d4>\u001b[0m in \u001b[0;36marena_stats\u001b[0;34m(Player_1, Player_2, board_shape, N)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Juega el jugador 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Juega el jugador 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-366-390596005c8f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mactions_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mactions_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbest_action_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.8/site-packages/boardgame2/env.py\u001b[0m in \u001b[0;36mnext_step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPASS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.8/site-packages/boardgame2/env.py\u001b[0m in \u001b[0;36mhas_valid\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.8/site-packages/boardgame2/reversi.py\u001b[0m in \u001b[0;36mis_valid\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arena_stats(GreedyPlayer,RandomPlayer, 8, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3f3ee8f6-6a86-41a6-8aca-4831ca280897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.35019455252918286\n",
      "Wins as second: 0.588477366255144\n",
      "Plays as first: 257\n",
      "Plays as second: 243\n",
      "Avg game duration: 11.752\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, RandomPlayer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2583b3c6-a24a-4737-bf4a-a9cb114f4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.4291497975708502\n",
      "Wins as second: 0.4980237154150198\n",
      "Plays as first: 247\n",
      "Plays as second: 253\n",
      "Avg game duration: 11.586\n"
     ]
    }
   ],
   "source": [
    "arena_stats(GreedyPlayer, GreedyPlayer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f1ae26ae-ad80-4111-8aa5-a24dd32e1773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.3804780876494024\n",
      "Wins as second: 0.3755020080321285\n",
      "Plays as first: 502\n",
      "Plays as second: 498\n",
      "Avg game duration: 57.943\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, GreedyPlayer, 8, N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e235c-b140-4989-8065-e03bf9fa40ca",
   "metadata": {},
   "source": [
    "# Guardar todas las clases de jugadores en un player.py para que luego se puedan importar de la siguiente forma:\n",
    "\n",
    "from players import RandomPlayer\n",
    "\n",
    "from players import GreedyPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366c04f-65a4-4464-8cdb-34103fe17d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
